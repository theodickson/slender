\begin{abstract}
Apache Spark is a parallel data processing framework with support for collections of arbitrary type. Though this allows the construction and processing of nested collections, severe performance issues are encountered when these inner collections exhibit skew due to the inability to distribute inner collections. Further, many nested queries are unable to be incrementalised efficiently. Attempts to rectify this often involve a technique called shredding, which decouples the nested collections from the main query and allows them to be parallelised and updated separately. However, many of the shredding transformations proposed have limited scope in the queries to which they can be applied, and are not offered as programmatic tools which can automatically transform queries.

In this work we develop a variant of the Nested Relational Calculus (NRC) which supports a compositional and generic shredding transformation. We implement it with a Scala DSL, which allows NRC queries to be expressed with natural and minimal syntax. The DSL can shred and evaluate queries on local Scala collections, Spark RDDs and Spark DStreams, and is easily extensible to other types of datasets. We also contribute several novel techniques for developing DSLs in Scala which are generally applicable to many similar tasks.

We obtain performance gains of up to 3.7x on shredded queries on Spark DStreams, although not all queries are sped up by shredding. We conclude that while shredding shows promise and this work contributes greatly to the ease of developing such query transformations for Spark, more work needs to be done in order to enable shredding to be a worthwhile optimisation to integrate with such frameworks.  
\end{abstract}